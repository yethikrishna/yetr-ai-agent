{"extracted_information": "The web content provides quickstart tutorials for developing clients that integrate with the Model Context Protocol (MCP) using various programming languages and frameworks. Each tutorial covers system requirements, environment setup, API key configuration, client code structure and logic, how to run the client, the client-server interaction workflow, best practices, and troubleshooting tips.\n\n**Python Client Quickstart**\n\n**Get Started:** Guides the user through building a LLM-powered chatbot client connecting to MCP servers.\n\n**System Requirements:**\n*   Mac or Windows computer\n*   Latest Python version installed\n*   Latest version of `uv` installed\n\n**Setting Up Your Environment:**\n1.  Create project directory: `uv init mcp-client`, `cd mcp-client`\n2.  Create virtual environment: `uv venv`\n3.  Activate virtual environment (Windows: `.venv\\Scripts\\activate`, Unix/MacOS: `source .venv/bin/activate`)\n4.  Install required packages: `uv add mcp anthropic python-dotenv`\n5.  Remove boilerplate files (Windows: `del main.py`, Unix/MacOS: `rm main.py`)\n6.  Create main file: `touch client.py`\n\n**Setting Up Your API Key:**\n1.  Obtain Anthropic API key from Anthropic Console.\n2.  Create `.env` file: `touch .env`\n3.  Add key to `.env`: `ANTHROPIC_API_KEY=<your key here>`\n4.  Add `.env` to `.gitignore`: `echo \".env\" >> .gitignore`\n\n**Creating the Client (`client.py`):**\n*   **Basic Client Structure:** Initializes `MCPClient` class with `ClientSession`, `AsyncExitStack`, and `Anthropic` client. Uses `dotenv` to load API key.\n    python\n    import asyncio\n    from typing import Optional\n    from contextlib import AsyncExitStack\n\n    from mcp import ClientSession, StdioServerParameters\n    from mcp.client.stdio import stdio_client\n\n    from anthropic import Anthropic\n    from dotenv import load_dotenv\n\n    load_dotenv()\n\n    class MCPClient:\n        def __init__(self):\n            self.session: Optional[ClientSession] = None\n            self.exit_stack = AsyncExitStack()\n            self.anthropic = Anthropic()\n    \n*   **Server Connection Management:** `connect_to_server` method takes server script path (`.py` or `.js`). Determines command (`python` or `node`). Creates `StdioServerParameters`. Uses `stdio_client` for transport. Enters session and initializes it. Lists available tools upon connection.\n    python\n    async def connect_to_server(self, server_script_path: str):\n        # ... validation and setup ...\n        server_params = StdioServerParameters(\n            command=command,\n            args=[server_script_path],\n            env=None\n        )\n\n        stdio_transport = await self.exit_stack.enter_async_context(stdio_client(server_params))\n        self.stdio, self.write = stdio_transport\n        self.session = await self.exit_stack.enter_async_context(ClientSession(self.stdio, self.write))\n\n        await self.session.initialize()\n\n        response = await self.session.list_tools()\n        tools = response.tools\n        print(\"\\nConnected to server with tools:\", [tool.name for tool in tools])\n    \n*   **Query Processing Logic:** `process_query` method. Sends user query to Claude (Anthropic API, model `claude-3-5-sonnet-20241022`) along with available tools listed from the MCP server. Processes Claude's response. If Claude requests a tool use, calls `self.session.call_tool()`, appends the result to messages, and makes another Claude API call with the tool results. Concatenates final text responses.\n    python\n    async def process_query(self, query: str) -> str:\n        messages = [\n            {\n                \"role\": \"user\",\n                \"content\": query\n            }\n        ]\n\n        # ... list tools ...\n\n        response = self.anthropic.messages.create(\n            model=\"claude-3-5-sonnet-20241022\",\n            max_tokens=1000,\n            messages=messages,\n            tools=available_tools\n        )\n\n        final_text = []\n        assistant_message_content = []\n        for content in response.content:\n            if content.type == 'text':\n                final_text.append(content.text)\n                assistant_message_content.append(content)\n            elif content.type == 'tool_use':\n                tool_name = content.name\n                tool_args = content.input\n\n                result = await self.session.call_tool(tool_name, tool_args)\n                # ... append results and call Claude again ...\n\n        return \"\\n\".join(final_text)\n    \n*   **Interactive Chat Interface:** `chat_loop` method provides a command-line interface. Prompts for input, calls `process_query`, prints response. Exits on 'quit'. Includes basic exception handling.\n*   **Cleanup:** `cleanup` method closes resources using `AsyncExitStack`.`\n*   **Main Entry Point:** `main` function handles command line arguments (server script path), creates `MCPClient`, connects, runs chat loop, and ensures cleanup using `finally`.\n\n**Key Components Explained:**\n*   **Client Initialization:** Sets up session management and API clients (Anthropic).\n*   **Server Connection:** Connects to Python/Node.js servers, validates script type, sets up communication, initializes session, lists tools.\n*   **Query Processing:** Manages conversation context, handles Claude responses and tool calls, manages message flow, combines results.\n*   **Interactive Interface:** Simple CLI, handles input/output, basic error handling, graceful exit.\n*   **Resource Management:** Proper cleanup using `AsyncExitStack`, error handling for connection issues, graceful shutdown.\n\n**Common Customization Points:** Tool handling, response processing, user interface.\n\n**Running the Client:**\n*   `uv run client.py path/to/server.py` (Python server)\n*   `uv run client.py path/to/build/index.js` (Node server)\n*   Example with weather server: `python client.py .../quickstart-resources/weather-server-python/weather.py`\n\n**How It Works:** Query -> Client gets tools -> Query+tools to Claude -> Claude decides tool use -> Client executes tools via server -> Results back to Claude -> Claude provides NL response -> Client displays response.\n\n**Best Practices:** Error Handling (try-catch tool calls, meaningful messages, graceful connection handling), Resource Management (AsyncExitStack, close connections), Security (secure API keys, validate server responses, caution with tool permissions).\n\n**Troubleshooting:** Server Path Issues (double-check path, use absolute path, correct slashes, correct extension), Response Timing (first response can be slow due to init/processing), Common Error Messages (FileNotFoundError, Connection refused, Tool execution failed, Timeout error).\n\n**TypeScript Client Quickstart**\n\n**System Requirements:**\n*   Mac or Windows computer\n*   Node.js 17 or higher installed\n*   Latest version of `npm` installed\n*   Anthropic API key (Claude)\n\n**Setting Up Your Environment:**\n1.  Create project directory: `mkdir mcp-client-typescript`, `cd mcp-client-typescript`\n2.  Initialize npm project: `npm init -y`\n3.  Install dependencies: `npm install @anthropic-ai/sdk @modelcontextprotocol/sdk dotenv`\n4.  Install dev dependencies: `npm install -D @types/node typescript`\n5.  Create source file: `touch index.ts`\n6.  Update `package.json` (set `type: \"module\"`, add `build` script).\n7.  Create `tsconfig.json`.\n\n**Setting Up Your API Key:**\n1.  Obtain Anthropic API key from Anthropic Console.\n2.  Create `.env` file: `echo \"ANTHROPIC_API_KEY=<your key here>\" > .env`\n3.  Add `.env` to `.gitignore`: `echo \".env\" >> .gitignore`\n\n**Creating the Client (`index.ts`):**\n*   **Basic Client Structure:** Imports necessary modules. Loads environment variables using `dotenv`. Checks for `ANTHROPIC_API_KEY`. Defines `MCPClient` class with `Client` from `@modelcontextprotocol/sdk/client`, `Anthropic` client, `StdioClientTransport`, and `tools` array.\n    typescript\n    import { Anthropic } from \"@anthropic-ai/sdk\";\n    // ... other imports ...\n    import dotenv from \"dotenv\";\n\n    dotenv.config();\n\n    const ANTHROPIC_API_KEY = process.env.ANTHROPIC_API_KEY;\n    // ... check key ...\n\n    class MCPClient {\n      private mcp: Client;\n      private anthropic: Anthropic;\n      private transport: StdioClientTransport | null = null;\n      private tools: Tool[] = [];\n\n      constructor() {\n        this.anthropic = new Anthropic({\n          apiKey: ANTHROPIC_API_KEY,\n        });\n        this.mcp = new Client({ name: \"mcp-client-cli\", version: \"1.0.0\" });\n      }\n    }\n    \n*   **Server Connection Management:** `connectToServer` method takes server script path (`.js` or `.py`). Determines command (`node` or `python`/`python3`). Creates `StdioClientTransport`. Connects `this.mcp` to the transport. Calls `this.mcp.listTools()`, maps results to `Tool` format, stores them. Logs connected tools.\n    typescript\n    async connectToServer(serverScriptPath: string) {\n      try {\n        // ... validation and command setup ...\n\n        this.transport = new StdioClientTransport({\n          command,\n          args: [serverScriptPath],\n        });\n        this.mcp.connect(this.transport);\n\n        const toolsResult = await this.mcp.listTools();\n        // ... map and store tools ...\n        console.log(\n          \"Connected to server with tools:\",\n          this.tools.map(({ name }) => name)\n        );\n      } catch (e) {\n        console.log(\"Failed to connect to MCP server: \", e);\n        throw e;\n      } catch {}\n    }\n    \n*   **Query Processing Logic:** `processQuery` method. Creates initial user message. Calls `this.anthropic.messages.create` with user message and available tools. Processes Claude's response content. If `type === 'text'`, appends text. If `type === 'tool_use'`, calls `this.mcp.callTool()`, appends tool call info to `finalText`, creates a new 'user' message with `tool_result` content, and calls Claude API again with updated messages. Appends the subsequent text response.\n    typescript\n    async processQuery(query: string) {\n      const messages: MessageParam[] = [\n        {\n          role: \"user\",\n          content: query,\n        },\n      ];\n\n      const response = await this.anthropic.messages.create({\n        model: \"claude-3-5-sonnet-20241022\",\n        max_tokens: 1000,\n        messages,\n        tools: this.tools,\n      });\n\n      const finalText = [];\n      const toolResults = [];\n\n      for (const content of response.content) {\n        if (content.type === \"text\") {\n          finalText.push(content.text);\n        } else if (content.type === \"tool_use\") {\n          const toolName = content.name;\n          const toolArgs = content.input as { [x: string]: unknown } | undefined;\n\n          const result = await this.mcp.callTool({\n            name: toolName,\n            arguments: toolArgs,\n          });\n          // ... handle tool result, update messages, call Claude again ...\n        }\n      }\n\n      return finalText.join(\"\\n\");\n    }\n    \n*   **Interactive Chat Interface:** `chatLoop` method uses `readline` for CLI input. Loops, prompts for query, calls `processQuery`, prints response. Exits on 'quit'. Closes `readline` interface in `finally`.\n*   **Cleanup:** `cleanup` method calls `this.mcp.close()`.`\n*   **Main Entry Point:** `main` async function checks for command line argument (server script path). Creates `MCPClient`, calls `connectToServer`, runs `chatLoop`, ensures `cleanup` and `process.exit(0)` in `finally`.\n\n**Running the Client:**\n1.  Build TypeScript: `npm run build`\n2.  Run client: `node build/index.js path/to/server.py` (Python) or `node build/index.js path/to/build/index.js` (Node)\n*   Example with weather server: `node build/index.js .../quickstart-resources/weather-server-typescript/build/index.js`\n\n**How It Works:** Same workflow as Python: Query -> Client gets tools -> Query+tools to Claude -> Claude decides tool use -> Client executes tools via server -> Results back to Claude -> Claude provides NL response -> Client displays response.\n\n**Best Practices:** Error Handling (TypeScript types, try-catch, meaningful messages, handle connection issues), Security (secure API keys, validate responses, caution with permissions).\n\n**Troubleshooting:** Server Path Issues (double-check path, use absolute path, correct slashes, correct extension), Response Timing (first response can be slow), Common Error Messages (Cannot find module, Connection refused, Tool execution failed, ANTHROPIC_API_KEY is not set, TypeError).\n\n**Spring AI (Java) Client Quickstart**\n\n**Get Started:** Demo using Spring AI MCP auto-configuration and boot starters to build an interactive chatbot integrating with Brave Search MCP Server.\n\n**System Requirements:**\n*   Java 17 or higher\n*   Maven 3.6+\n*   npx package manager\n*   Anthropic API key (Claude)\n*   Brave Search API key\n\n**Setting Up Your Environment:**\n1.  Install npx (requires npm): `npm install -g npx`\n2.  Clone repository: `git clone https://github.com/spring-projects/spring-ai-examples.git`, `cd model-context-protocol/brave-chatbot`\n3.  Set up API keys (as environment variables): `export ANTHROPIC_API_KEY='your-anthropic-api-key-here'`, `export BRAVE_API_KEY='your-brave-api-key-here'`\n4.  Build application: `./mvnw clean install`\n5.  Run application: `./mvnw spring-boot:run`\n\n**How it Works (Integration Components):**\n*   **MCP Client Configuration:**\n    *   Dependencies in `pom.xml`: `spring-ai-starter-mcp-client`, `spring-ai-starter-model-anthropic`.\n    *   Application properties (`application.yml`): Enables `spring.ai.mcp.client`, configures name, version, type (`SYNC`), request timeout, stdio settings (`root-change-notification`, `servers-configuration`), and `toolcallback.enabled=true` (registers MCP tools as Spring AI tools). Configures Anthropic API key.\n    *   MCP Server Configuration (`mcp-servers-config.json`): Defines MCP servers, e.g., `brave-search` with `command` (`npx`), `args` (`-y`, `@modelcontextprotocol/server-brave-search`), and `env` (`BRAVE_API_KEY`).\n*   **Chat Implementation:** Uses `ChatClientBuilder`. Sets a default system prompt. Registers MCP tools using `.defaultToolCallbacks((Object[]) mcpToolAdapter.toolCallbacks())` (Note: use `.defaultToolCallbacks` from 1.0.0-M8+). Adds message memory using `MessageChatMemoryAdvisor` and `InMemoryChatMemory`. Builds the `ChatClient`.\n\n**Build and Run:**\n*   `./mvnw clean install`\n*   `java -jar ./target/ai-mcp-brave-chatbot-0.0.1-SNAPSHOT.jar` or `./mvnw spring-boot:run`\n*   Starts an interactive chat session.\n\n**Chatbot Capabilities:** Answers using built-in knowledge, performs web searches via Brave Search (when needed), remembers conversation context, combines information.\n\n**Advanced Configuration:** Client customization (`McpSyncClientCustomizer`/`McpAsyncClientCustomizer`), multiple clients/transports (`STDIO`, `SSE`), integration with Spring AI tool execution, automatic lifecycle management. WebFlux starter available for SSE transport.\n\n**Kotlin Client Quickstart**\n\n**System Requirements:**\n*   Java 17 or higher\n*   Anthropic API key (Claude)\n\n**Setting up your environment:**\n1.  Install `java` and `gradle`. Verify `java --version`.\n2.  Create a new directory: `mkdir kotlin-mcp-client`, `cd kotlin-mcp-client`\n3.  Initialize Kotlin project using `gradle init` (select Application, Kotlin, Java 17) or IntelliJ IDEA.\n4.  Add dependencies to `build.gradle.kts` or `build.gradle`: `kotlin-sdk`, `slf4j-nop`, `anthropic-java`. Specify versions (`mcpVersion`, `slf4jVersion`, `anthropicVersion`).\n5.  Add `shadow` plugin.\n\n**Setting up your API key:**\n1.  Obtain Anthropic API key.\n2.  Set as environment variable: `export ANTHROPIC_API_KEY='your-anthropic-api-key-here'`.\n\n**Creating the Client:**\n*   **Basic Client Structure:** Defines `MCPClient` class implementing `AutoCloseable`. Initializes `anthropic` using `AnthropicOkHttpClient.fromEnv()` and `mcp` using `Client`. Declares `tools` list. Implements `close()` to close `mcp` and `anthropic` using `runBlocking`.\n    kotlin\n    class MCPClient : AutoCloseable {\n        private val anthropic = AnthropicOkHttpClient.fromEnv()\n        private val mcp: Client = Client(clientInfo = Implementation(name = \"mcp-client-cli\", version = \"1.0.0\"))\n        private lateinit var tools: List<ToolUnion>\n\n        override fun close() {\n            runBlocking {\n                mcp.close()\n                anthropic.close()\n            }\n        }\n    }\n    \n*   **Server connection management:** `connectToServer` suspend function takes server script path (`.js`, `.py`, or `.jar`). Determines command based on extension (`node`, `python`/`python3`, `java -jar`). Starts process using `ProcessBuilder`. Creates `StdioClientTransport` from process input/output streams. Connects `mcp` to the transport. Calls `mcp.listTools()`, maps the result to `ToolUnion` format, and stores in `tools`. Logs connected tools.\n    kotlin\n    suspend fun connectToServer(serverScriptPath: String) {\n        try {\n            // ... command determination ...\n\n            val process = ProcessBuilder(command).start()\n            val transport = StdioClientTransport(\n                input = process.inputStream.asSource().buffered(),\n                output = process.outputStream.asSink().buffered()\n            )\n\n            mcp.connect(transport)\n\n            val toolsResult = mcp.listTools()\n            tools = toolsResult?.tools?.map { tool ->\n                // ... map tool details ...\n            } ?: emptyList()\n            println(\"Connected to server with tools: ${tools.joinToString(\", \") { it.tool().get().name() }}\")\n        } catch (e: Exception) {\n            println(\"Failed to connect to MCP server: $e\")\n            throw e\n        }\n    }\n    \n    Includes a helper function `toJsonValue` for `JsonObject` conversion.\n*   **Query processing logic:** `processQuery` suspend function takes a query. Builds initial user message. Calls `anthropic.messages().create` with messages and tools. Processes Claude's response (`isText()`, `isToolUse()`). If `isToolUse()`, calls `mcp.callTool()`, adds tool call info to `finalText`, adds a new user message with tool result, calls Claude again. Appends the final text response.\n    kotlin\n    private val messageParamsBuilder: MessageCreateParams.Builder = MessageCreateParams.builder()\n        .model(Model.CLAUDE_3_5_SONNET_20241022)\n        .maxTokens(1024)\n\n    suspend fun processQuery(query: String): String {\n        // ... initial messages ...\n\n        val response = anthropic.messages().create(\n            messageParamsBuilder\n                .messages(messages)\n                .tools(tools)\n                .build()\n        )\n\n        val finalText = mutableListOf<String>()\n        response.content().forEach { content ->\n            when {\n                content.isText() -> finalText.add(content.text().getOrNull()?.text() ?: \"\")\n\n                content.isToolUse() -> {\n                    // ... call mcp.callTool(), update messages, call Claude again ...\n                }\n            }\n        }\n\n        return finalText.joinToString(\"\\n\", prefix = \"\", postfix = \"\")\n    }\n    \n*   **Interactive chat:** `chatLoop` suspend function provides a CLI using `readLine`. Loops, prompts for query, calls `processQuery`, prints response. Exits on 'quit'.\n*   **Main entry point:** `main` function uses `runBlocking`. Checks for command line argument (server path). Creates `MCPClient`, uses `client.use` for `AutoCloseable` management, calls `connectToServer` and `chatLoop`.\n\n**Running the client:**\n1.  Build: `./gradlew build`\n2.  Run: `java -jar build/libs/<your-jar-name>.jar path/to/server.jar` (JVM), `... server.py` (Python), or `... build/index.js` (Node).\n*   Example with weather server: `java -jar build/libs/kotlin-mcp-client-0.1.0-all.jar .../samples/weather-stdio-server/build/libs/weather-stdio-server-0.1.0-all.jar`\n\n**How it works:** Same workflow as Python: Query -> Client gets tools -> Query+tools to Claude -> Claude decides tool use -> Client executes tools via server -> Results back to Claude -> Claude provides NL response -> Client displays response.\n\n**Best practices:** Error Handling (Kotlin types, try-catch, meaningful messages, handle connection issues), Security (secure API keys, validate responses, caution with permissions).\n\n**Troubleshooting:** Server Path Issues (double-check path, use absolute path, correct slashes, required runtime installed, correct extension), Response Timing (first response can be slow), Common Error Messages (Connection refused, Tool execution failed, ANTHROPIC_API_KEY is not set).\n\n**C# Client Quickstart**\n\n**System Requirements:**\n*   .NET 8.0 or higher\n*   Anthropic API key (Claude)\n*   Windows, Linux, or MacOS\n\n**Setting up your environment:**\n1.  Create new .NET project: `dotnet new console -n QuickstartClient`, `cd QuickstartClient`\n2.  Add dependencies: `dotnet add package ModelContextProtocol --prerelease`, `dotnet add package Anthropic.SDK`, `dotnet add package Microsoft.Extensions.Hosting`\n\n**Setting up your API key:**\n1.  Obtain Anthropic API key.\n2.  Initialize user secrets: `dotnet user-secrets init`\n3.  Set user secret: `dotnet user-secrets set \"ANTHROPIC_API_KEY\" \"<your key here>\"`\n\n**Creating the Client (`Program.cs`):**\n*   **Basic Client Structure:** Sets up `Host.CreateApplicationBuilder` and adds configuration sources (Environment Variables, User Secrets). Includes a helper function `GetCommandAndArguments` to determine server command based on script extension (`.py`, `.js`, `.csproj` directory/file). Creates `StdioClientTransport`. Creates `McpClient` using `McpClientFactory.CreateAsync()`. Lists tools upon connection.\n    csharp\n    using Anthropic.SDK;\n    // ... other imports ...\n\n    var builder = Host.CreateApplicationBuilder(args);\n\n    builder.Configuration\n        .AddEnvironmentVariables()\n        .AddUserSecrets<Program>();\n\n    var (command, arguments) = GetCommandAndArguments(args);\n\n    var clientTransport = new StdioClientTransport(new()\n    {\n        Name = \"Demo Server\",\n        Command = command,\n        Arguments = arguments,\n    });\n\n    await using var mcpClient = await McpClientFactory.CreateAsync(clientTransport);\n\n    var tools = await mcpClient.ListToolsAsync();\n    foreach (var tool in tools)\n    {\n        Console.WriteLine($\"Connected to server with tools: {tool.Name}\");\n    }\n\n    static (string command, string[] arguments) GetCommandAndArguments(string[] args)\n    {\n        // ... implementation ...\n    }\n    \n*   **Query processing logic:** Sets up `AnthropicClient` using `Microsoft.Extensions.AI`'s `UseFunctionInvocation` extension for automatic tool calling. Configures `ChatOptions` with model (`claude-3-5-sonnet-20241022`), max tokens, and the listed MCP tools. Enters a chat loop, prompts for input, calls `anthropicClient.GetStreamingResponseAsync`, and writes the streaming response to the console. Exits on 'exit'. Includes `PromptForInput` helper.\n    csharp\n    using var anthropicClient = new AnthropicClient(new APIAuthentication(builder.Configuration[\"ANTHROPIC_API_KEY\"]))\n        .Messages\n        .AsBuilder()\n        .UseFunctionInvocation()\n        .Build();\n\n    var options = new ChatOptions\n    {\n        MaxOutputTokens = 1000,\n        ModelId = \"claude-3-5-sonnet-20241022\",\n        Tools = [.. tools]\n    };\n\n    // ... chat loop ...\n    while(Console.ReadLine() is string query && !\"exit\".Equals(query, StringComparison.OrdinalIgnoreCase))\n    {\n        // ... handle empty query ...\n        await foreach (var message in anthropicClient.GetStreamingResponseAsync(query, options))\n        {\n            Console.Write(message);\n        }\n        Console.WriteLine();\n\n        PromptForInput();\n    }\n\n    static void PromptForInput()\n    {\n        // ... prompt text ...\n    }\n    \n\n**Key Components Explained:**\n*   **Client Initialization:** Uses `McpClientFactory.CreateAsync()` to set up transport and server command.\n*   **Server Connection:** Supports Python, Node.js, and .NET servers. Starts server via command line, uses stdio, initializes session and tools.\n*   **Query Processing:** Leverages `Microsoft.Extensions.AI` for chat client with automatic tool (function) invocation. Reads input, sends to server/LLM, displays response.\n\n**Running the Client:**\n*   `dotnet run -- path/to/server.csproj` (.NET server)\n*   `dotnet run -- path/to/server.py` (Python server)\n*   `dotnet run -- path/to/server.js` (Node server)\n*   Example with weather server: `dotnet run -- path/to/QuickstartWeatherServer`\n*   Connects, lists tools, starts interactive chat.\n\n**Next steps:** Links to Example servers, Clients, Building MCP with LLMs, Core architecture."}